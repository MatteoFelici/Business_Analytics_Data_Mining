{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - New tools for Data Scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first lesson we will see the main tools of the Anaconda environment for data analysis and code development; then we will learn how to read from and write to different kind of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anaconda (https://www.anaconda.com/) is a free platform for Python usage, inclusive of:\n",
    "- a package-management system, called _conda_\n",
    "- a series of tools for Python programming, all accessible from _Anaconda Navigator_ interface\n",
    "- a development environment with all the most important packages for scientific programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conda\n",
    "Conda (https://docs.conda.io/projects/conda/en/latest/#) is an open source system for package and environment mangement. We can use it for:\n",
    "- create a new environment, defined by a Python version and a series of installed packages (each with a specific version)<br>\n",
    "    *conda create --name env_name python=version_num package_1 package_2*\n",
    "- clone an existing environment, to replicate the results of a project<br>\n",
    "    *conda create --name env_name -f=packages_file.yaml*\n",
    "- install, uninstall, update all the Python packages present on all the distribution channels<br>\n",
    "    *conda install package*<br>\n",
    "    *pip install package*\n",
    "\n",
    "The default active environment is _base_. If we want to activate (use) another one:<br>\n",
    "    *conda activate env_name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anaconda Navigator\n",
    "With this interface we can:\n",
    "- open tools like Jupyter Notebook, Spyder and QTConsole\n",
    "- manage packages and environments in a more \"visual\" way\n",
    "- find links to documentation and community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read, write, explore and process data we will use _pandas_ libray (https://pandas.pydata.org/): it is the _de facto_ framework to use data in Python.<br>\n",
    "\n",
    "![title](./img/pandas_logo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base structure we will use is the _DataFrame_, a 2-dimension table (rows x columns) to represent \"structured\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'col_1': ['A', 'B', 'C', 'B'], 'col_2': [1, 5, 7, 3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leftmost number is the __index__: it is an univocal number assigned to each record. It's the column name equivalent for rows.<br>\n",
    "We can use an existing column as index, using the parameter *index_col* while reading data or the function *set_index* in any moment; the default index is a progressive integer starting from 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input --- read_csv:** https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main parameters:\n",
    "- _sep_: symbol to separate data, default ','\n",
    "- *use_cols*: list of columns to import; if not specified, it imports all the columns\n",
    "- _skiprows_ & *n_rows*: list of rows (or number of rows) to skip / number of rows to read; if not specified, it imports all the data\n",
    "- *na_values*: list to values equivalent to **missing**\n",
    "- *parse_dates*: list of columns to treat as dates\n",
    "- _dtype_: dictionary of columns types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv('./Data/input/base_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamental functions/attributes to analyse the dataset:\n",
    "- _head(n)_: first _n_ rows\n",
    "- _tail(n)_: last _n_ rows\n",
    "- _dtypes_: column types\n",
    "- _shape_: dataset dimension (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _object_ columns contain categorical / mixed data.\n",
    "We can notice that *loan_dt* and *birth_dt* are NOT automatically recognised as dates. Moreover, customer NDG is seen as integer and not code (_str_).\n",
    "\n",
    "#### _Exercise_\n",
    "re-read the file using *parse_dates* e _dtype_ parameters to correct the issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Exercise_\n",
    "Import the file of the bank account balances, *account_bal.csv*, into the dataframe *df_balance*. The output dataframe must have the correct data types.<br>_Tip: pay attention to sep parameter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output --- to_csv:** https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main parameters:\n",
    "- *columns*: list of columns to export; if not specified, it exports all the columns\n",
    "- *index*: if **True** (as default), the index is written in output file; if **False** the index is omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.to_csv('./Data/file_prova.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input --- read_excel:** https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main parameters:\n",
    "- all from *read_csv*\n",
    "- *sheet_name*: name of the sheet from which read the data; we can also set a number (starting from 0). If not specified, it reads the first sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse the Excel file without opening it, we can use the _ExcelFile_ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelfile = pd.ExcelFile('./Data/input/input_data.xlsx')\n",
    "\n",
    "print(excelfile.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_services = pd.read_excel('./Data/input/input_data.xlsx',\n",
    "                            sheet_name='service_registry',\n",
    "                            parse_dates=['serv_start_dt', 'serv_end_dt'],\n",
    "                            dtype={'NDG': str})\n",
    "\n",
    "df_services.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output --- to_excel:** https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main parameters:\n",
    "- all from *to_csv*\n",
    "- *sheet_name*: name of output sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining *to_excel* with *ExcelWriter* class, we can write several sheets without overwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('./excel_foo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_services.to_excel(writer, sheet_name='registry', index=False)\n",
    "\n",
    "df_foo = pd.DataFrame({'col_1': ['A', 'B', 'C', 'B'], 'col_2': [1, 5, 7, 3]})\n",
    "df_foo.to_excel(writer, sheet_name='foo', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to close the file object to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read data from a _sqlite_ database, so we will use the _sqlite3_ library to create a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('./Data/input/input_data.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input --- read_sql:** https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main parameters:\n",
    "- the first parameter (_sql_) can be the input table name __or__ an SQL query\n",
    "- the second parameter (_con_) is a connection to database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading the *sqlite_master* table we can extrapolate all the info of the database and its tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('select * from sqlite_master', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov = pd.read_sql('account_mov', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Exercise_\n",
    "Import *loans_data* table into dataframe *df_loans*, excluding the rows where *loan_type* is equal to UNSECURED value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write to database, we can use the same methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output --- to_sql:** https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loans.to_sql('loans_secured', engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (badm_env)",
   "language": "python",
   "name": "badm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
